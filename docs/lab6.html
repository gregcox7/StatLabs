<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Lab 6 Sampling and the Central Limit Theorem: The Wisdom of Large Samples | Labs</title>
<meta name="author" content="Greg Cox">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.9/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4/tabs.js"></script><script src="libs/bs3compat-0.2.4/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="css/ims-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Labs</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Overview</a></li>
<li><a class="" href="lab1.html"><span class="header-section-number">1</span> Exploring Data with R</a></li>
<li><a class="" href="lab2.html"><span class="header-section-number">2</span> Central tendency and variability</a></li>
<li><a class="" href="lab3.html"><span class="header-section-number">3</span> Scatterplots and correlation</a></li>
<li><a class="" href="lab4.html"><span class="header-section-number">4</span> Probability and simulation</a></li>
<li><a class="" href="lab5.html"><span class="header-section-number">5</span> Models: The Binomial and the Normal</a></li>
<li><a class="active" href="lab6.html"><span class="header-section-number">6</span> Sampling and the Central Limit Theorem: The Wisdom of Large Samples</a></li>
<li><a class="" href="lab7.html"><span class="header-section-number">7</span> Confidence intervals and hypothesis testing</a></li>
<li><a class="" href="lab8.html"><span class="header-section-number">8</span> Statistical Power</a></li>
<li><a class="" href="lab9.html"><span class="header-section-number">9</span> \(t\) tests</a></li>
<li><a class="" href="lab10.html"><span class="header-section-number">10</span> Comparing Independent Samples</a></li>
<li><a class="" href="lab11.html"><span class="header-section-number">11</span> Linear Regression</a></li>
<li><a class="" href="lab12.html"><span class="header-section-number">12</span> Exploring Data with R, Part II</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="coderef.html"><span class="header-section-number">A</span> Distributions</a></li>
<li><a class="" href="hyptests.html"><span class="header-section-number">B</span> Hypothesis Tests</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/gregcox7/StatLabs">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="lab6" class="section level1" number="6">
<h1>
<span class="header-section-number">Lab 6</span> Sampling and the Central Limit Theorem: The Wisdom of Large Samples<a class="anchor" aria-label="anchor" href="#lab6"><i class="fas fa-link"></i></a>
</h1>
<div class="inline-figure"><img src="img/crowd.png" width="100%"></div>
<p>We have just encountered a remarkable phenomenon which goes by the weighty but unclear name “central limit theorem.” This theorem says that if we draw a large enough sample from our population of interest, the <em>mean</em> of our sample will have a much better chance of being a good <em>estimate</em> of the mean of the population.</p>
<p>Specifically, what happens is that there is a distribution of sample means which is approximately normal. The mean of this distribution is the population mean (which we’ve labeled <span class="math inline">\(\mu\)</span>) and the standard deviation of this distribution is called the “<strong>standard error of the mean</strong>” and is equal to <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>, where <span class="math inline">\(\sigma\)</span> is the population standard deviation and <span class="math inline">\(n\)</span> is our sample size. So this distribution of sample means is centered on the “correct answer,” and gets narrower and narrower the larger our sample. This means that, the larger the sample, the better the chance that its mean is close to the population mean.</p>
<p>But for this to happen, our sample has to be <em>representative</em> of the population. If the sample is <em>biased</em> in any way, then our estimate of the population mean will also be biased. One way a sample can be biased is if it is not a <em>simple random sample</em> from the population.</p>
<p>In this session, we will see the “central limit theorem” in action to better understand what it means. We will also see how sampling bias hampers our ability to estimate population means. Finally, we will see that it is not just a statistical curiosity, but something that is surprisingly pervasive.</p>
<div id="before-we-begin" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Before we begin…<a class="anchor" aria-label="anchor" href="#before-we-begin"><i class="fas fa-link"></i></a>
</h2>
<p>For this session, we will need the tidyverse package like usual. We will <em>also</em> need another package from R’s library called “infer.” Make sure you have it installed (if you already have it installed, you can skip the next line, but try running this line if something doesn’t work):</p>
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"infer"</span><span class="op">)</span></code></pre></div>
<p>Now, make sure you have loaded <em>both</em> the tidyverse package <em>and</em> the new “infer” package from R’s library:</p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></code></pre></div>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
## ✓ tibble  3.1.3     ✓ dplyr   1.0.5
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.0     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<div class="sourceCode" id="cb221"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tidymodels/infer">infer</a></span><span class="op">)</span></code></pre></div>
<p>One last thing before we begin: Make your best guess about the answer to this question: <strong>What percent of the world’s airports are in the United States?</strong></p>
</div>
<div id="heights" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Heights<a class="anchor" aria-label="anchor" href="#heights"><i class="fas fa-link"></i></a>
</h2>
<p>Last time, we saw how when we used a <em>model</em> to simulate lots of individual observed values, the descriptive statistics for our simulated data were very close to the model <em>parameters</em> we used. We focused on the distribution of these individual values. Now, we will focus on the <strong>distribution of sample means</strong>. This is the distribution that represents our uncertainty about the true value of the population mean.</p>
<div id="a-simulated-population" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> A simulated population<a class="anchor" aria-label="anchor" href="#a-simulated-population"><i class="fas fa-link"></i></a>
</h3>
<p>Lets use the normal distribution to simulate the heights of an entire population of women, let’s say 50,000. Remember that the mean height is 64 inches and the standard deviation is 6 inches:</p>
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50000</span>, mean <span class="op">=</span> <span class="fl">64</span>, sd <span class="op">=</span> <span class="fl">6</span><span class="op">)</span>

<span class="va">population</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">height</span><span class="op">)</span></code></pre></div>
<p>In the first line, we used the <code>rnorm</code> function to simulate the heights of <code>n = 50000</code> women, where the average height is <code>mean = 64</code> inches and the standard deviation of heights is <code>sd = 6</code> inches. We told R to remember this collection of values under the name “height.” In the second line, we told R to treat “height” as if it were data (a “tibble”) and told R to remember our data under the name “population.”</p>
</div>
<div id="a-sample-from-our-simulated-population" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> A sample from our simulated population<a class="anchor" aria-label="anchor" href="#a-sample-from-our-simulated-population"><i class="fas fa-link"></i></a>
</h3>
<p>Now that we have a whole population at our disposal—which we can only do because we are <em>simulating them</em>!—we can experiment and see what the effect is of getting different samples from this population.</p>
<p>The code below selects a simple random sample of 10 women from our population:</p>
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 1
##    height
##     &lt;dbl&gt;
##  1   55.2
##  2   56.8
##  3   58.9
##  4   65.6
##  5   65.0
##  6   52.0
##  7   58.1
##  8   52.6
##  9   59.5
## 10   65.3</code></pre>
<p>This is pretty similar to how we simulated things like coin flips earlier.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Compare sampling from a population to simulating coin flips. When we select an individual from a population, what is the &lt;em&gt;sample space&lt;/em&gt;? If we are doing simple random sampling, what is the probability that any particular individual is selected into our sample?&lt;/p&gt;"><sup>63</sup></a> The <code>slice_sample</code> function is just another way we can simulate drawing a “sample” of size <code>n</code> from a set of possibilities.</p>
<p>Let’s try it again and see what a different sample of 10 women from this population might be:</p>
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 1
##    height
##     &lt;dbl&gt;
##  1   64.5
##  2   67.8
##  3   55.9
##  4   60.7
##  5   66.3
##  6   69.0
##  7   74.7
##  8   57.0
##  9   54.8
## 10   64.3</code></pre>
<p>Now let’s tell R to remember one of these samples under the name “sample_heights,” so we can work with it later.</p>
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_heights</span> <span class="op">&lt;-</span> <span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></code></pre></div>
<p>Now we can do our usual thing and find the mean and standard deviation of the heights <em>in this one sample</em>:</p>
<div class="sourceCode" id="cb228"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_heights</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span>, S <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##       M     S
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  64.9  5.73</code></pre>
<p>As we might expect, they are somewhat close to the parameters we used to generate the population, but they are unlikely to match exactly.</p>
</div>
<div id="many-samples-from-our-simulated-population" class="section level3" number="6.2.3">
<h3>
<span class="header-section-number">6.2.3</span> Many samples from our simulated population<a class="anchor" aria-label="anchor" href="#many-samples-from-our-simulated-population"><i class="fas fa-link"></i></a>
</h3>
<p>If we kept getting samples of size 10 from our population, how often would their sample means be close to the true population mean? While we could just keep running that same code from above over and over again, R helps us automate this process:</p>
<div class="sourceCode" id="cb230"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">many_samples_size10</span> <span class="op">&lt;-</span> <span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://infer.tidymodels.org/reference/rep_sample_n.html">rep_slice_sample</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, reps <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></code></pre></div>
<p>What we just did was use the <code>rep_slice_sample</code> function to <code>rep</code>eatedly sample groups of 10 women from our population<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Compare this line of code with the line we used to get a single sample of size 10, above. What is similar and what is different?&lt;/p&gt;"><sup>64</sup></a>. Specifically, we got <code>reps = 1000</code> samples of size 10, and we told R to remember these samples under the name “many_samples_size10.” Let’s have a look at what the resulting simulated data look like:</p>
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">many_samples_size10</span></code></pre></div>
<pre><code>## # A tibble: 10,000 × 2
## # Groups:   replicate [1,000]
##    replicate height
##        &lt;int&gt;  &lt;dbl&gt;
##  1         1   65.3
##  2         1   72.3
##  3         1   69.6
##  4         1   67.1
##  5         1   69.0
##  6         1   70.4
##  7         1   67.6
##  8         1   54.5
##  9         1   56.2
## 10         1   55.1
## # … with 9,990 more rows</code></pre>
<p>So there are two columns, one column is “height,” representing the height in inches of each simulated woman in our samples. The other column is “replicate” which tells us <em>which sample</em> (of the 1000 samples we made) the woman is in. This column will let us group the women into their respective samples.</p>
<p>Now we can get the mean height for each sample:</p>
<div class="sourceCode" id="cb233"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">many_samples_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">replicate</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1,000 × 2
##    replicate     M
##        &lt;int&gt; &lt;dbl&gt;
##  1         1  64.7
##  2         2  67.3
##  3         3  62.5
##  4         4  60.8
##  5         5  63.0
##  6         6  64.6
##  7         7  62.2
##  8         8  66.1
##  9         9  64.1
## 10        10  60.6
## # … with 990 more rows</code></pre>
<p>So we begin to see how the sample mean changes depending on who happened to have been selected into the sample. But this is still too many numbers, so let’s go to our old standby, the histogram.</p>
<p>First, let’s tell R to remember those sample means we just found:</p>
<div class="sourceCode" id="cb235"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size10</span> <span class="op">&lt;-</span> <span class="va">many_samples_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">replicate</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Now, we are in shape to make a histogram representing the <em>frequency</em> with which different samples have different means:</p>
<div class="sourceCode" id="cb236"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">M</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span>binwidth<span class="op">=</span><span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-central_limit_files/figure-html/unnamed-chunk-13-1.png" width="672"></div>
<p>Certainly looks like a normal distribution! Now let’s see what the mean and standard deviation of the sample means are:</p>
<div class="sourceCode" id="cb237"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>MM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span>, SEM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##      MM   SEM
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  64.0  1.93</code></pre>
<p>Remember that the standard deviation of sample means goes by the special name <strong>standard error of the mean</strong>, hence why we labeled it <code>SEM</code>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Based on the “central limit theorem,” and the fact that the population standard deviation is &lt;span class="math inline"&gt;\(\sigma = 6\)&lt;/span&gt; and the samples are of size &lt;span class="math inline"&gt;\(n = 10\)&lt;/span&gt;, how does the value of &lt;code&gt;SEM&lt;/code&gt; above compare with what the central limit theorem would predict?&lt;/p&gt;'><sup>65</sup></a></p>
</div>
<div id="many-larger-samples" class="section level3" number="6.2.4">
<h3>
<span class="header-section-number">6.2.4</span> Many larger samples<a class="anchor" aria-label="anchor" href="#many-larger-samples"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s follow the same steps above, but instead of collecting many samples of size 10, let’s get many larger samples of size 100.</p>
<p>First, let’s simulate 1000 samples, all of size 100, and tell R to remember them under the name “many_samples_size100.”<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;What code would do this? &lt;em&gt;Hint: what would you need to change in the code we used to produce many samples of size 10?&lt;/em&gt;&lt;/p&gt;"><sup>66</sup></a></p>
<p>Next, let’s find the means of each of those samples like we did above:</p>
<div class="sourceCode" id="cb239"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size100</span> <span class="op">&lt;-</span> <span class="va">many_samples_size100</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">replicate</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>And have a look at a histogram:</p>
<div class="sourceCode" id="cb240"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size100</span> <span class="op">%&gt;%</span>
    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">M</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span>binwidth<span class="op">=</span><span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-central_limit_files/figure-html/unnamed-chunk-17-1.png" width="672"></div>
<p>And the mean of sample means and standard error of the mean<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Compare &lt;code&gt;SEM&lt;/code&gt; we found for our samples of size 100 with what the central limit theorem says the standard error of the mean should be—is it close? Compare &lt;code&gt;SEM&lt;/code&gt; for samples of size 10 to &lt;code&gt;SEM&lt;/code&gt; for samples of size 100, which is smaller?&lt;/p&gt;"><sup>67</sup></a>:</p>
<div class="sourceCode" id="cb241"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size100</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>MM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span>, SEM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##      MM   SEM
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  64.0 0.600</code></pre>
</div>
<div id="the-probability-of-being-wrong" class="section level3" number="6.2.5">
<h3>
<span class="header-section-number">6.2.5</span> The probability of being wrong<a class="anchor" aria-label="anchor" href="#the-probability-of-being-wrong"><i class="fas fa-link"></i></a>
</h3>
<p>Remember that, just like we never really get to see the whole population in any real-world settings, we also never really get to see the distribution of sample means in real life. In real life, we will probably only have one sample and, therefore, one sample mean.</p>
<p>But because our sample mean comes from a distribution of sample means that is <em>normal</em>, we can use the normal distribution to figure out the <em>probability</em> that whatever sample mean we have is wrong, and by how much.</p>
<div id="using-simulation" class="section level4" number="6.2.5.1">
<h4>
<span class="header-section-number">6.2.5.1</span> Using simulation<a class="anchor" aria-label="anchor" href="#using-simulation"><i class="fas fa-link"></i></a>
</h4>
<p>First, let’s use our many simulated samples to see how many are wrong by different amounts.</p>
<p>How many of our samples of size 10 had sample means that under-shot or over-shot the true population mean of 64 inches?</p>
<div class="sourceCode" id="cb243"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">M</span> <span class="op">&gt;</span> <span class="fl">64</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>n<span class="op">=</span><span class="fu">n</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">mutate</span><span class="op">(</span>p <span class="op">=</span> <span class="va">n</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   `M &gt; 64`     n     p
##   &lt;lgl&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 FALSE      497 0.497
## 2 TRUE       503 0.503</code></pre>
<p>In the second line above, we grouped our samples by whether or not their sample means were greater than 64 (<code>M &gt; 64</code>). Looks like it is about even.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;By counting the number of samples that over-shot, we also end up knowing how many samples under-shot. Why is this?&lt;/p&gt;"><sup>68</sup></a> This suggests that the sample means are not <em>biased</em> either high or low.</p>
<p>Now, how many of our samples of size 10 had sample means that were within 1 inch of the true population mean of 64 inches? In other words, how many had sample means that were between 63 and 65 inches?</p>
<div class="sourceCode" id="cb245"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sample_means_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="fl">63</span> <span class="op">&lt;</span> <span class="va">M</span> <span class="op">&amp;</span> <span class="va">M</span> <span class="op">&lt;</span> <span class="fl">65</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>n<span class="op">=</span><span class="fu">n</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">mutate</span><span class="op">(</span>p <span class="op">=</span> <span class="va">n</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   `63 &lt; M &amp; M &lt; 65`     n     p
##   &lt;lgl&gt;             &lt;int&gt; &lt;dbl&gt;
## 1 FALSE               600   0.6
## 2 TRUE                400   0.4</code></pre>
<p>By comparison, how many of our samples of size 100 had sample means that were within 1 inch of the true population mean of 64 inches?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;What code produces the results below? &lt;em&gt;Hint: what should we change in the code immediately above?&lt;/em&gt;&lt;/p&gt;"><sup>69</sup></a></p>
<pre><code>## # A tibble: 2 × 3
##   `63 &lt; M &amp; M &lt; 65`     n     p
##   &lt;lgl&gt;             &lt;int&gt; &lt;dbl&gt;
## 1 FALSE                97 0.097
## 2 TRUE                903 0.903</code></pre>
<p>Wow, that’s quite an improvement! The probability that our estimate of the population mean—the sample mean—is within 1 inch of the correct answer is much higher if our sample has 100 women than 10 women.</p>
</div>
<div id="using-the-central-limit-theorem" class="section level4" number="6.2.5.2">
<h4>
<span class="header-section-number">6.2.5.2</span> Using the central limit theorem<a class="anchor" aria-label="anchor" href="#using-the-central-limit-theorem"><i class="fas fa-link"></i></a>
</h4>
<p>Remember that we were only able to count those results above <em>because we have many many samples of the same size</em>. In real life, we almost never have this. That’s why the central limit theorem is useful—we can use what we know about the normal distribution to calculate the probability of being wrong and by how much.</p>
<p>Let’s first think about our samples of size 10. The central limit theorem says that the means of these samples have a normal distribution with a mean of <span class="math inline">\(\mu = 64\)</span> inches and a standard deviation of <span class="math inline">\(\frac{\sigma}{\sqrt{n}} = \frac{6}{\sqrt{10}} \left( \approx 1.897 \right)\)</span> inches. In R, we can write that standard deviation like this: <code>6 / sqrt(10)</code>, where <code>sqrt</code> stands for “square root.”</p>
<p>Now, using the normal distribution, what is the probability that the mean we get from a sample of size 10 is within 1 inch of the true population mean?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;How does the probability we get from the normal distribution compare with the one we found by counting our samples, above?&lt;/p&gt;"><sup>70</sup></a></p>
<div class="sourceCode" id="cb248"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span>q<span class="op">=</span><span class="fl">65</span>, mean <span class="op">=</span> <span class="fl">64</span>, sd <span class="op">=</span> <span class="fl">6</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">63</span>, mean <span class="op">=</span> <span class="fl">64</span>, sd <span class="op">=</span> <span class="fl">6</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 0.4018385</code></pre>
<p>And what is the probability that the mean we get from a sample of size 100 is within 1 inch of the true population mean?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;What code produces this result? &lt;em&gt;Hint: what do we need to change in the code above?&lt;/em&gt;&lt;/p&gt;"><sup>71</sup></a></p>
<pre><code>## [1] 0.9044193</code></pre>
</div>
</div>
<div id="biased-samples" class="section level3" number="6.2.6">
<h3>
<span class="header-section-number">6.2.6</span> Biased samples<a class="anchor" aria-label="anchor" href="#biased-samples"><i class="fas fa-link"></i></a>
</h3>
<p>So far, we assumed that our samples were all simple random samples. What happens if this is no longer the case? What if instead our samples are <strong>biased</strong>?</p>
<p>Imagine that instead of selecting women at random, we got a bunch of women in a large room and selected them based on how easy they were to see. Obviously this would lead us to select more tall than short women, because it is easier to see a tall person above a crowd (and a tall person could hide a shorter person behind them). We can simulate this kind of biased sampling by telling R to give more “weight” to a woman who is taller when selecting samples. This doesn’t mean that a short person will <em>never</em> get selected (maybe they are standing in front so no one is in the way), but it does make it less likely.</p>
<p>Here’s an example of a single sample of size 10, where more “weight” is given to women who are taller:</p>
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, weight_by <span class="op">=</span> <span class="va">height</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 1
##    height
##     &lt;dbl&gt;
##  1   65.6
##  2   62.5
##  3   65.7
##  4   65.2
##  5   62.4
##  6   60.2
##  7   46.7
##  8   57.6
##  9   74.8
## 10   62.3</code></pre>
<p>Now let’s repeat the same steps from above to get 1000 <em>biased</em> samples each of size 10 and size 100 (note that this may take longer than simulating unbiased samples):</p>
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">many_biased_samples_size10</span> <span class="op">&lt;-</span> <span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://infer.tidymodels.org/reference/rep_sample_n.html">rep_slice_sample</a></span><span class="op">(</span>n<span class="op">=</span><span class="fl">10</span>, reps<span class="op">=</span><span class="fl">1000</span>, weight_by <span class="op">=</span> <span class="va">height</span><span class="op">)</span>

<span class="va">many_biased_samples_size100</span> <span class="op">&lt;-</span> <span class="va">population</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://infer.tidymodels.org/reference/rep_sample_n.html">rep_slice_sample</a></span><span class="op">(</span>n<span class="op">=</span><span class="fl">100</span>, reps<span class="op">=</span><span class="fl">1000</span>, weight_by <span class="op">=</span> <span class="va">height</span><span class="op">)</span></code></pre></div>
<p>Now let’s get the means of each of these biased samples:</p>
<div class="sourceCode" id="cb254"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">biased_sample_means_size10</span> <span class="op">&lt;-</span> <span class="va">many_biased_samples_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">replicate</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span><span class="op">)</span>

<span class="va">biased_sample_means_size100</span> <span class="op">&lt;-</span> <span class="va">many_biased_samples_size100</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">replicate</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">height</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Let’s look at some histograms to get a sense of their distribution shape. Here it is for biased samples of size 10:</p>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">biased_sample_means_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">M</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span>binwidth<span class="op">=</span><span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-central_limit_files/figure-html/unnamed-chunk-27-1.png" width="672"></div>
<p>And for biased samples of size 100<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Do the shapes of the distributions of biased means still look roughly normal, or do they look a bit skewed? Is there a difference between biased samples of size 10 vs. 100?&lt;/p&gt;"><sup>72</sup></a>:</p>
<div class="sourceCode" id="cb256"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">biased_sample_means_size100</span> <span class="op">%&gt;%</span>
    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">M</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span>binwidth<span class="op">=</span><span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-central_limit_files/figure-html/unnamed-chunk-28-1.png" width="672"></div>
<p>And finally, let’s have a look at the mean of the sample means and their standard errors for biased samples of size 10:</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">biased_sample_means_size10</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>MM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span>, SEM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##      MM   SEM
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  64.6  1.84</code></pre>
<p>And for biased samples of size 100<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;What is different between the mean of sample means (&lt;code&gt;MM&lt;/code&gt;) and the standard error of the mean (&lt;code&gt;SEM&lt;/code&gt;) for biased samples versus unbiased samples? Does this difference make sense given the way our samples are biased?&lt;/p&gt;"><sup>73</sup></a>:</p>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">biased_sample_means_size100</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>MM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span>, SEM <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##      MM   SEM
##   &lt;dbl&gt; &lt;dbl&gt;
## 1  64.6 0.606</code></pre>
</div>
</div>
<div id="the-wisdom-of-the-crowd" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> The Wisdom of the Crowd<a class="anchor" aria-label="anchor" href="#the-wisdom-of-the-crowd"><i class="fas fa-link"></i></a>
</h2>
<p>We’ve seen how, at least when we have simple random samples, the larger a sample, the more likely it is that our sample mean is close to the actual population mean. But this isn’t just a statistical curiosity about estimating properties of populations, like their heights. It turns out that if you want to know anything about the world, you’re better off asking more people. This concept was originally identified by <span class="citation"><a href="references.html#ref-Galton1907" role="doc-biblioref">Galton</a> (<a href="references.html#ref-Galton1907" role="doc-biblioref">1907</a>)</span> and is now called the “wisdom of the crowd” <span class="citation">(<a href="references.html#ref-Surowiecki2004" role="doc-biblioref">Surowiecki, 2004</a>)</span>.</p>
<p>The wisdom of crowds was studied recently by <span class="citation"><a href="references.html#ref-SteegenEtAl2014" role="doc-biblioref">Steegen et al.</a> (<a href="references.html#ref-SteegenEtAl2014" role="doc-biblioref">2014</a>)</span> who replicated a study by <span class="citation"><a href="references.html#ref-VulPashler2008" role="doc-biblioref">Vul &amp; Pashler</a> (<a href="references.html#ref-VulPashler2008" role="doc-biblioref">2008</a>)</span>. They asked people questions about world facts like the one you answered at the beginning of the session. These people weren’t experts and weren’t allowed to look up the answer. But as we will see, their <em>mean</em> answer is actually pretty close to the truth.</p>
<div id="grab-the-data" class="section level3" number="6.3.1">
<h3>
<span class="header-section-number">6.3.1</span> Grab the data<a class="anchor" aria-label="anchor" href="#grab-the-data"><i class="fas fa-link"></i></a>
</h3>
<p>First, let’s download the guesses that the participants in <span class="citation"><a href="references.html#ref-SteegenEtAl2014" role="doc-biblioref">Steegen et al.</a> (<a href="references.html#ref-SteegenEtAl2014" role="doc-biblioref">2014</a>)</span> made to the question you answered at the beginning:</p>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">wisdom_data</span> <span class="op">&lt;-</span> <span class="fu">read_csv</span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/gregcox7/StatLabs/main/data/wisdom.csv"</span><span class="op">)</span></code></pre></div>
<pre><code>## Rows: 471 Columns: 4</code></pre>
<pre><code>## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: ","
## chr (2): nationality, sex
## dbl (2): age, guess</code></pre>
<pre><code>## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<p>Taking a look at the data, each row represents a different person’s answer to the question. The answer they gave is in the “guess” column. There is also some demographic information about each person (age, sex, nationality).</p>
</div>
<div id="make-a-histogram" class="section level3" number="6.3.2">
<h3>
<span class="header-section-number">6.3.2</span> Make a histogram<a class="anchor" aria-label="anchor" href="#make-a-histogram"><i class="fas fa-link"></i></a>
</h3>
<p>Now let’s make a histogram of people’s guesses<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Why do you think the histogram looks kind of “lumpy?” &lt;em&gt;Hint: how much detail do you think people can give when making a guess like this?&lt;/em&gt;&lt;/p&gt;"><sup>74</sup></a>:</p>
<div class="sourceCode" id="cb265"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">wisdom_data</span> <span class="op">%&gt;%</span>
    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">guess</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-central_limit_files/figure-html/unnamed-chunk-32-1.png" width="672"></div>
<p>Doesn’t look especially normal, but it is also pretty spread out. This makes sense given that very few if any people in this sample would be expected to be experts in airport distribution.</p>
</div>
<div id="what-is-the-right-answer" class="section level3" number="6.3.3">
<h3>
<span class="header-section-number">6.3.3</span> What is the right answer?<a class="anchor" aria-label="anchor" href="#what-is-the-right-answer"><i class="fas fa-link"></i></a>
</h3>
<p>At the time these data were collected, the correct answer to the question, “what percent of the world’s airports are in the United States?” was <strong>32.3%</strong> (how close were you?).</p>
<p>How many people over- or under-shot the answer?</p>
<div class="sourceCode" id="cb266"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">wisdom_data</span> <span class="op">%&gt;%</span>
    <span class="fu">group_by</span><span class="op">(</span><span class="va">guess</span> <span class="op">&lt;</span> <span class="fl">32.3</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>n <span class="op">=</span> <span class="fu">n</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">mutate</span><span class="op">(</span>p <span class="op">=</span> <span class="va">n</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   `guess &lt; 32.3`     n     p
##   &lt;lgl&gt;          &lt;int&gt; &lt;dbl&gt;
## 1 FALSE            155 0.329
## 2 TRUE             316 0.671</code></pre>
</div>
<div id="what-about-the-average" class="section level3" number="6.3.4">
<h3>
<span class="header-section-number">6.3.4</span> What about the average?<a class="anchor" aria-label="anchor" href="#what-about-the-average"><i class="fas fa-link"></i></a>
</h3>
<p>How close was the <em>mean</em> guess to the right answer?</p>
<div class="sourceCode" id="cb268"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">wisdom_data</span> <span class="op">%&gt;%</span>
    <span class="fu">summarize</span><span class="op">(</span>M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">guess</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##       M
##   &lt;dbl&gt;
## 1  27.0</code></pre>
<p>Huh, not too bad! The difference between the mean guess and the right answer is about <span class="math inline">\(32.3 - 27 = 5.3\)</span>. How many people were at least as close to the correct answer as the mean guess, in other words, how many people guessed a value between 27 and <span class="math inline">\(32.3 + 5.3 = 37.6\)</span>?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;What code would give us this result? &lt;em&gt;Hint: remember how we found the number of sample mean heights that were within an inch of the true population average above.&lt;/em&gt;&lt;/p&gt;"><sup>75</sup></a></p>
<pre><code>## # A tibble: 2 × 3
##   `27 &lt; guess &amp; guess &lt; 37.6`     n     p
##   &lt;lgl&gt;                       &lt;int&gt; &lt;dbl&gt;
## 1 FALSE                         380 0.807
## 2 TRUE                           91 0.193</code></pre>
<p>So the mean guess is doing better than the vast majority of individual guesses. This is pretty remarkable! The “wisdom of the crowd” is another case in which large samples get us closer to the truth.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Why do you think that the &lt;em&gt;mean&lt;/em&gt; of a set of guesses does so much better than most of the individual guesses?&lt;/p&gt;"><sup>76</sup></a></p>
</div>
</div>
<div id="wrap-up-5" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Wrap-up<a class="anchor" aria-label="anchor" href="#wrap-up-5"><i class="fas fa-link"></i></a>
</h2>
<p>We’ve seen the “central limit theorem” in action: The larger our sample, the more likely it is that the sample mean is close to the population mean. This is valuable because, in reality, we almost never know the true population mean, so we have to <em>estimate</em> it using a sample. But we also saw that a <em>biased</em> sample can give us the wrong answer. Finally, we saw that the power of large samples extends to making guesses about the world at large—maybe instead of finding an expert, we just need a lot of guesses!</p>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="lab5.html"><span class="header-section-number">5</span> Models: The Binomial and the Normal</a></div>
<div class="next"><a href="lab7.html"><span class="header-section-number">7</span> Confidence intervals and hypothesis testing</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#lab6"><span class="header-section-number">6</span> Sampling and the Central Limit Theorem: The Wisdom of Large Samples</a></li>
<li><a class="nav-link" href="#before-we-begin"><span class="header-section-number">6.1</span> Before we begin…</a></li>
<li>
<a class="nav-link" href="#heights"><span class="header-section-number">6.2</span> Heights</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-simulated-population"><span class="header-section-number">6.2.1</span> A simulated population</a></li>
<li><a class="nav-link" href="#a-sample-from-our-simulated-population"><span class="header-section-number">6.2.2</span> A sample from our simulated population</a></li>
<li><a class="nav-link" href="#many-samples-from-our-simulated-population"><span class="header-section-number">6.2.3</span> Many samples from our simulated population</a></li>
<li><a class="nav-link" href="#many-larger-samples"><span class="header-section-number">6.2.4</span> Many larger samples</a></li>
<li><a class="nav-link" href="#the-probability-of-being-wrong"><span class="header-section-number">6.2.5</span> The probability of being wrong</a></li>
<li><a class="nav-link" href="#biased-samples"><span class="header-section-number">6.2.6</span> Biased samples</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#the-wisdom-of-the-crowd"><span class="header-section-number">6.3</span> The Wisdom of the Crowd</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#grab-the-data"><span class="header-section-number">6.3.1</span> Grab the data</a></li>
<li><a class="nav-link" href="#make-a-histogram"><span class="header-section-number">6.3.2</span> Make a histogram</a></li>
<li><a class="nav-link" href="#what-is-the-right-answer"><span class="header-section-number">6.3.3</span> What is the right answer?</a></li>
<li><a class="nav-link" href="#what-about-the-average"><span class="header-section-number">6.3.4</span> What about the average?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#wrap-up-5"><span class="header-section-number">6.4</span> Wrap-up</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/gregcox7/StatLabs/blob/master/06-central_limit.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/gregcox7/StatLabs/edit/master/06-central_limit.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Labs</strong>" was written by Greg Cox. It was last built on 2021-08-18.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
